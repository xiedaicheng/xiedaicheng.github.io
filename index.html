<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  

  
  <title></title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title">
  
    <link rel="alternate" href="/atom.xml" title="" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  
    <link href="//fonts.googleapis.com/css?family=Source+Code+Pro" rel="stylesheet" type="text/css">
  
  <link rel="stylesheet" href="/css/style.css">
</head>
</html>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo"></a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://yoursite.com"></form>
      </div>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main">
  
    <article id="post-AI入门课程资源" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/01/12/AI入门课程资源/" class="article-date">
  <time datetime="2019-01-12T02:51:13.000Z" itemprop="datePublished">2019-01-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/01/12/AI入门课程资源/">AI入门课程资源</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="企业"><a href="#企业" class="headerlink" title="企业"></a>企业</h2><h3 id="kaggle"><a href="#kaggle" class="headerlink" title="kaggle"></a>kaggle</h3><p>　　<a href="https://www.kaggle.com/learn/overview" target="_blank" rel="noopener">https://www.kaggle.com/learn/overview</a></p>
<h3 id="Google"><a href="#Google" class="headerlink" title="Google"></a>Google</h3><p>   <a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1547038525&amp;ver=1317&amp;signature=p4MuVqr63rRrJENd0*1h6wNsM8JexhywOqO0V-FIasanPV16mzlsKzeYBptrTL*AGncdSYTHOpK1WapfL-Q6sJwJiMl7jB3ADNo7DTq-cG4AnmqXTaoHCKC5UzCHKdra&amp;new=1" target="_blank" rel="noopener">介绍</a></p>
<p>　　<a href="https://developers.google.cn/machine-learning/crash-course/" target="_blank" rel="noopener">https://developers.google.cn/machine-learning/crash-course/</a></p>
<p>　　<a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1547038525&amp;ver=1317&amp;signature=vZDz0LzHmNDIjYOkcetRJi5mv1zQCkJU2I46QKRCxmhrfqBB13BY7Zc377RcQJLH5N2gGTOg3pWVx9bKuF*T7rSKnAMCuxc*s8uHsAKhs37BZ4Cf5vIvcU8UeN7yi4L9&amp;new=1" target="_blank" rel="noopener">GFW内视频</a></p>
<h3 id="微软"><a href="#微软" class="headerlink" title="微软"></a>微软</h3><p>　　<a href="https://school.azure.cn/curriculums/28" target="_blank" rel="noopener">https://school.azure.cn/curriculums/28</a> （暂不可用）</p>
<p>　　<a href="https://aischool.microsoft.com/en-us/machine-learning/learning-paths" target="_blank" rel="noopener">https://aischool.microsoft.com/en-us/machine-learning/learning-paths</a></p>
<p>　　<a href="https://academy.microsoft.com/en-us/professional-program/tracks/data-science/" target="_blank" rel="noopener">https://academy.microsoft.com/en-us/professional-program/tracks/data-science/</a></p>
<h3 id="亚马逊AWS"><a href="#亚马逊AWS" class="headerlink" title="亚马逊AWS　　"></a>亚马逊AWS　　</h3><p>　　<a href="https://amazonaws-china.com/cn/training/learning-paths/machine-learning/?nc1=h_ls" target="_blank" rel="noopener">https://amazonaws-china.com/cn/training/learning-paths/machine-learning/?nc1=h_ls</a></p>
<h2 id="学院"><a href="#学院" class="headerlink" title="学院"></a>学院</h2><pre><code>吴恩达机器学习
</code></pre><p>　　<a href="https://study.163.com/course/introduction/1004570029.htm" target="_blank" rel="noopener">https://study.163.com/course/introduction/1004570029.htm</a></p>
<p>　　吴恩达 deeplearning.ai 神经网络和深度学习</p>
<p>　　<a href="https://mooc.study.163.com/course/2001281002?_trace_c_p_k2_=d15f1572a13f4c02b0ee86e9fd1d2d2f#/info" target="_blank" rel="noopener">https://mooc.study.163.com/course/2001281002?_trace_c_p_k2_=d15f1572a13f4c02b0ee86e9fd1d2d2f#/info</a></p>
<p>　　斯坦福吴恩达深度学习  <a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1547036344&amp;ver=1317&amp;signature=Gx4nyYH8gTYP9*MPLlAzJzYiCwUAqS58MECTLfMqQND-qAAH0TCdd*0zVI6gWgymlfHBmygAP7vRKB7nUULjIuASFXNeJANdz4aJckuV0TBKS2NCbvdLOd9cFr5rlRSE&amp;new=1" target="_blank" rel="noopener">介绍</a></p>
<p>　　<a href="https://web.stanford.edu/class/cs230/" target="_blank" rel="noopener">https://web.stanford.edu/class/cs230/</a></p>
<p>　　斯坦福计算机视觉</p>
<p>　　<a href="https://study.163.com/course/introduction/1004697005.htm" target="_blank" rel="noopener">https://study.163.com/course/introduction/1004697005.htm</a></p>
<p>　　 <a href="http://vision.stanford.edu/teaching/cs231n/" target="_blank" rel="noopener">http://vision.stanford.edu/teaching/cs231n/</a></p>
<pre><code>斯坦福NLP

https://open.163.com/movie/2018/8/P/6/MDOV6DET8_MDOV7B9P6.html

http://web.stanford.edu/class/cs224n/
</code></pre><p>　　CMU深度学习</p>
<pre><code>http://www.mooc.ai/course/562

http://www.cs.cmu.edu/~tom/10701_sp11/

台湾大学林轩田机器学习

上：https://www.coursera.org/learn/ntumlone-mathematicalfoundations

下：https://www.coursera.org/learn/ntumlone-algorithmicfoundations
</code></pre><h2 id="网红"><a href="#网红" class="headerlink" title="网红"></a>网红</h2><p>　　《神经网络与深度学习》　 Michael Nielsen　</p>
<p>　　<a href="http://neuralnetworksanddeeplearning.com/" target="_blank" rel="noopener">http://neuralnetworksanddeeplearning.com/</a> </p>
<p>　　<a href="https://xhhjin.gitbooks.io/neural-networks-and-deep-learning-zh/content/cover.html" target="_blank" rel="noopener">中文版</a>  　<a href="files.meetup.com/18520925/nndl-ebook%20%283%29.pdf">中文版pdf</a></p>
<p>　　fast.ai</p>
<p>　　<a href="https://course.fast.ai/" target="_blank" rel="noopener">https://course.fast.ai/</a></p>
<p>　　Oleksii Trekhleb <a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1547040665&amp;ver=1317&amp;signature=vZDz0LzHmNDIjYOkcetRJi5mv1zQCkJU2I46QKRCxmgALuxkY2wAaifJmaXfpa4hTiNsO6L3YB61D0SuEpu-A9AqtWJzHLPoAjautofNkWrPbxgMG7MZ8u6D*ePyYk7k&amp;new=1" target="_blank" rel="noopener">介绍</a></p>
<p>　　<a href="https://github.com/trekhleb/homemade-machine-learning" target="_blank" rel="noopener">https://github.com/trekhleb/homemade-machine-learning</a></p>
<p>　　TensorFlow <a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1547040809&amp;ver=1317&amp;signature=vZDz0LzHmNDIjYOkcetRJi5mv1zQCkJU2I46QKRCxmj9hLXy*SO2NTkrUwmG-Ty4HKg6EqM-Nv16zRkxSttmwsKtRi3QKz7Bi17AFji8QK6A98jsvt7SQxhQ8QVglsYk&amp;new=1" target="_blank" rel="noopener">介绍</a></p>
<p>　　<a href="https://github.com/open-source-for-science/TensorFlow-Course#why-use-tensorflow" target="_blank" rel="noopener">https://github.com/open-source-for-science/TensorFlow-Course#why-use-tensorflow</a></p>
<p>　　 PracticalAI <a href="https://mp.weixin.qq.com/s?src=11&amp;timestamp=1547040809&amp;ver=1317&amp;signature=vZDz0LzHmNDIjYOkcetRJi5mv1zQCkJU2I46QKRCxmj9usc*uFoFMVZK5SeIlGZ3xsivf0bMYv04UGxpvwVVtiLDqT2SGUHWsTrtVNCV-iVPVb54HQlhIKmqihvrjGSr&amp;new=1" target="_blank" rel="noopener">介绍</a></p>
<p>　　 <a href="https://github.com/GokuMohandas/practicalAI/" target="_blank" rel="noopener">https://github.com/GokuMohandas/practicalAI/</a></p>
<p>　　Avik-Jain</p>
<p>　　<a href="https://github.com/Avik-Jain/100-Days-Of-ML-Code" target="_blank" rel="noopener">https://github.com/Avik-Jain/100-Days-Of-ML-Code</a></p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/01/12/AI入门课程资源/" data-id="cjqsvkk7h0000t9gqasuq7b10" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  
    <article id="post-感知机" class="article article-type-post" itemscope="" itemprop="blogPost">
  <div class="article-meta">
    <a href="/2019/01/12/感知机/" class="article-date">
  <time datetime="2019-01-12T02:40:40.000Z" itemprop="datePublished">2019-01-12</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/01/12/感知机/">感知机</a>
    </h1>
  

      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>　　概念</p>
<p>　　感知机是一种二元线性分类器。输入一组代表实例特征的向量，感知机可以计算出实例的类别。</p>
<p>　　二元分类指的是感知机输出的结果只有两类，代表是或否。实际应用中，一些问题要求的输出就是是或否，比如根据照片识别性别，识别图片中是否存在某种物品，根据X光片判断是否患病，判断邮件是否是垃圾邮件等等。</p>
<p>　　多个是或否的判断嵌套叠加起来，就可以处理复杂的逻辑，也可以输出多元分类。所以，使用多个类似感知机的分类器，组合成一个计算模型，可以解决多种复杂的识别/决策问题。这样的一个计算模型被叫做人工神经网络，其中的单个分类器被叫做人工神经元。</p>
<p>　　数学模型</p>
<p>　　感知机的数学模型是：</p>
<p>　　　　<img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4e1ed056a43771fc10b5222c5c49b4d853e3b174" alt=""></p>
<p>　　x是代表实例特征的一维数组<img src="https://latex.codecogs.com/gif.latex?\inline&space;\inline&amp;space;[x_{1},x_{2},...,x_{n}]" alt=""></p>
<p>　　w是代表每个特征权重的一维数组<img src="https://latex.codecogs.com/gif.latex?\inline&space;\inline&amp;space;[w_{1},w_{2},...,w_{n}]" alt=""></p>
<p>　　 <img src="https://latex.codecogs.com/gif.latex?\inline&space;\inline&amp;space;w\cdot&amp;space;x" alt="">是两个数组的<a href="https://zh.wikipedia.org/wiki/%E7%82%B9%E7%A7%AF" target="_blank" rel="noopener">点积</a><br><img src="https://latex.codecogs.com/gif.latex?\inline&space;\inline&amp;space;\sum_{i=1}^{n}&amp;space;w_{i}x_{i}&amp;space;=&amp;space;w_{1}x_{1}+w_{2}x_{2}+...+w_{n}x_{n}" alt=""></p>
<p>　　b是一个代表偏置的常数</p>
<p>　　当<img src="https://latex.codecogs.com/gif.latex?\inline&space;\inline&amp;space;w\cdot&amp;space;x+b&gt;0" alt="">时，感知机输出1，代表结果为true，神经元被激活；否则输出0，代表结果为false，神经元未被激活。 </p>
<p>　　几何含义： <img src="https://latex.codecogs.com/gif.latex?\inline&space;\inline&amp;space;w\cdot&amp;space;x+b=0" alt="">这一超平面，把空间分隔成两部分</p>
<p> 　　应用示例</p>
<p>　　用感知机来实现并运算：取<img src="https://latex.codecogs.com/gif.latex?\inline&space;\inline&amp;space;w_{1}&amp;space;=&amp;space;1" alt="">,<img src="https://latex.codecogs.com/gif.latex?\inline&space;\inline&amp;space;w_{2}&amp;space;=&amp;space;1" alt="">,<img src="https://latex.codecogs.com/gif.latex?\inline&space;\inline&amp;space;b&amp;space;=&amp;space;1.5" alt="">, 对于以下输入通过感知机计算得出y值和并运算真值表的相同，这样我们就通过感知机模拟了一个并运算函数。</p>
<table>
<thead>
<tr>
<th><img src="https://latex.codecogs.com/gif.latex?\inline&space;\inline&amp;space;x_{1}" alt=""></th>
<th><img src="https://latex.codecogs.com/gif.latex?\inline&space;\inline&amp;space;x_{2}" alt=""></th>
<th><img src="https://latex.codecogs.com/gif.latex?\inline&space;\inline&amp;space;y" alt=""></th>
</tr>
</thead>
<tbody>
<tr>
<td> 1</td>
<td>0</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td> 0</td>
<td>1</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td> 0</td>
<td>0</td>
<td>0</td>
<td></td>
</tr>
<tr>
<td> 1</td>
<td>1</td>
<td>1</td>
<td></td>
</tr>
</tbody>
</table>
<p> 　　下图展示了真值表的坐标，和一条代表感知机的直线。<br><img src="https://img2018.cnblogs.com/blog/641139/201901/641139-20190103205733725-1433351409.png" alt="">
　　</p>
<p>　　能正确分类的直线有无数条。w和b也有无数种正确的取值。</p>
<p>　　并运算只有四个样本，两个特征，是一个最简单的例子。通常我们要处理的问题有更多样本，更多特征。</p>
<p>　　感知器可以拟合任何的线性函数，可以用来解决任何线性分类。但是解决不了线性不可分的问题，对于线性不可分问题，需要通过多个感知机组成的网络来处理。</p>
<p>　　训练</p>
<p>　　使用给定样本，寻找权重w和偏置b的过程，叫做训练</p>
<p>　　训练算法：</p>
<p>　　　　设置w和b默认值为0，然后不断迭代更新，直到能正确分类所有样本</p>
<p>　　<img src="https://latex.codecogs.com/gif.latex?\inline&space;w_{i}\leftarrow&amp;space;w_{i}+\bigtriangleup&amp;space;w_{i}" alt=""></p>
<p>　　<img src="https://latex.codecogs.com/gif.latex?\inline&space;b\leftarrow&amp;space;b+\bigtriangleup&amp;space;b" alt=""></p>
<p>　　其中</p>
<p>　　<br><img src="https://latex.codecogs.com/gif.latex?\inline&space;\Delta&space;w_{i}=(t-y" alt="">x_{i})<br>　　<br><img src="https://latex.codecogs.com/gif.latex?\inline&space;\Delta&space;b=\eta&space;(t-y" alt="">)</p>
<p>　　t代表训练样本的实际值，被称为label，y代表使用当前参数感知机的输出值，<img src="https://latex.codecogs.com/gif.latex?\inline&space;\eta" alt="">代表学习率，是一个需要手工设定的超参数。</p>
<p>　　下面的代码定义了一个包含训练方法的感知机类型。</p>
<pre><code>class Perceptron(object):
    def __init__(self, input_num, activator):
        &apos;&apos;&apos;
        初始化感知器，设置输入参数的个数，以及激活函数。
        激活函数的类型为double -&gt; double
        &apos;&apos;&apos;
        self.activator = activator
        # 权重向量初始化为0
        self.weights = [0.0 for _ in range(input_num)]
        # 偏置项初始化为0
        self.bias = 0.0
    def __str__(self):
        &apos;&apos;&apos;
        打印学习到的权重、偏置项
        &apos;&apos;&apos;
        return &apos;weights\t:%s\nbias\t:%f\n&apos; % (self.weights, self.bias)
    def predict(self, input_vec):
        &apos;&apos;&apos;
        输入向量，输出感知器的计算结果
        &apos;&apos;&apos;
        # 把input_vec[x1,x2,x3...]和weights[w1,w2,w3,...]打包在一起
        # 变成[(x1,w1),(x2,w2),(x3,w3),...]
        # 然后利用map函数计算[x1*w1, x2*w2, x3*w3]
        # 最后利用reduce求和
        return self.activator(
            reduce(lambda a, b: a + b,
                   map(lambda (x, w): x * w,  
                       zip(input_vec, self.weights))
                , 0.0) + self.bias)
    def train(self, input_vecs, labels, iteration, rate):
        &apos;&apos;&apos;
        输入训练数据：一组向量、与每个向量对应的label；以及训练轮数、学习率
        &apos;&apos;&apos;
        for i in range(iteration):
            self._one_iteration(input_vecs, labels, rate)
    def _one_iteration(self, input_vecs, labels, rate):
        &apos;&apos;&apos;
        一次迭代，把所有的训练数据过一遍
        &apos;&apos;&apos;
        # 把输入和输出打包在一起，成为样本的列表[(input_vec, label), ...]
        # 而每个训练样本是(input_vec, label)
        samples = zip(input_vecs, labels)
        # 对每个样本，按照感知器规则更新权重
        for (input_vec, label) in samples:
            # 计算感知器在当前权重下的输出
            output = self.predict(input_vec)
            # 更新权重
            self._update_weights(input_vec, output, label, rate)
    def _update_weights(self, input_vec, output, label, rate):
        &apos;&apos;&apos;
        按照感知器规则更新权重
        &apos;&apos;&apos;
        # 把input_vec[x1,x2,x3,...]和weights[w1,w2,w3,...]打包在一起
        # 变成[(x1,w1),(x2,w2),(x3,w3),...]
        # 然后利用感知器规则更新权重
        delta = label - output
        self.weights = map(
            lambda (x, w): w + rate * delta * x,
            zip(input_vec, self.weights))
        # 更新bias
        self.bias += rate * delta
</code></pre><p> 　　使用这个类来训练一个并函数</p>
<pre><code>def f(x):
    &apos;&apos;&apos;
    定义激活函数f
    &apos;&apos;&apos;
    return 1 if x &gt; 0 else 0
def get_training_dataset():
    &apos;&apos;&apos;
    基于and真值表构建训练数据
    &apos;&apos;&apos;
    # 构建训练数据
    # 输入向量列表
    input_vecs = [[1,1], [0,0], [1,0], [0,1]]
    # 期望的输出列表，注意要与输入一一对应
    # [1,1] -&gt; 1, [0,0] -&gt; 0, [1,0] -&gt; 0, [0,1] -&gt; 0
    labels = [1, 0, 0, 0]
    return input_vecs, labels    
def train_and_perceptron():
    &apos;&apos;&apos;
    使用and真值表训练感知器
    &apos;&apos;&apos;
    # 创建感知器，输入参数个数为2（因为and是二元函数），激活函数为f
    p = Perceptron(2, f)
    # 训练，迭代10轮, 学习速率为0.1
    input_vecs, labels = get_training_dataset()
    p.train(input_vecs, labels, 10, 0.1)
    #返回训练好的感知器
    return p
if __name__ == &apos;__main__&apos;: 
    # 训练and感知器
    and_perception = train_and_perceptron()
    # 打印训练获得的权重
    print and_perception
    # 测试
    print &apos;1 and 1 = %d&apos; % and_perception.predict([1, 1])
    print &apos;0 and 0 = %d&apos; % and_perception.predict([0, 0])
    print &apos;1 and 0 = %d&apos; % and_perception.predict([1, 0])
    print &apos;0 and 1 = %d&apos; % and_perception.predict([0, 1])
</code></pre>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2019/01/12/感知机/" data-id="cjqsvkk7q0001t9gqlnbs04i1" class="article-share-link">Share</a>
      
      
    </footer>
  </div>
  
</article>


  


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2019/01/">January 2019</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2019/01/12/AI入门课程资源/">AI入门课程资源</a>
          </li>
        
          <li>
            <a href="/2019/01/12/感知机/">感知机</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2019 XieDaiCheng<br>
      Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>



  </div>
</body>
</html>